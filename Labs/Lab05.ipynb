{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear averaging dynamics\n",
    "In the first part of the lab we study linear averaging dynamics on graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $G=(V,E,W)$ be a weighted graph, and $x(t) \\in \\mathrm{R}^{V}$ denote the state of the nodes of the graph.\n",
    "\n",
    "The dynamics of $x(t)$ reads\n",
    "\n",
    "$$\n",
    "x(t+1) = Px(t),\n",
    "$$\n",
    "\n",
    "where $P$ is the normalized adjacency matrix.\n",
    "Among the applications, the most popular is opinion dynamics, where $x_i$ indicates the opinion of node $i$. This dynamics is known as French - De Groot.\n",
    "\n",
    "Note that we assume by convention that the opinion of node $i$ is influenced by the opinion of node $j$ if $P_{ij}>0$, i.e., the link $(i,j)$ is to be interpreted as $i$ watching $j$ and updating her opinion based on opinion of $j$.\n",
    "\n",
    "**Observation**: observe that $\\mathbf{1}$ is an equilibrium distribution, since $\\mathbf{1} = P \\mathbf{1}$ ($P$ is row-stochastic by construction), i.e., consensus distributions are equilibria of the dynamics.\n",
    "\n",
    "**Question**: what are the conditions under which the dynamics converges to consensus?\n",
    "\n",
    "**Theorem**: assume that\n",
    "- its condensation graph has 1 sink;\n",
    "- the sink component of the graph is aperiodic;\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} x(t) = \\alpha \\mathbf{1},\n",
    "$$\n",
    "\n",
    "i.e., the agents get to consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why aperiodicity matters: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.generators.lattice.grid_graph(dim=[2,2])\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the graph is periodic because of every cycle has even length (the graph is bipartite and undirected, thus its period is 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary that maps the label of nodes  \n",
    "# (from (0,0) to (2,1)) to their index (from 0 to n_nodes-1)\n",
    "indices = dict()\n",
    "for i in range(n_nodes):\n",
    "    indices[list(G.nodes)[i]] = i\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign initial opinion to nodes and run the dynamics\n",
    "x = np.array([1,0,0,1])\n",
    "\n",
    "nodecolor=x*1000\n",
    "\n",
    "# plot centrality at iteration 0\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes with opinion 1 are red, nodes with opinion 0 are white.\n",
    "\n",
    "After one iteration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = P @ x\n",
    "\n",
    "nodecolor=x*1000\n",
    "\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "print(\"x(1):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect after 5 iterations from the initial condition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = P @ P @ P @ P @ x\n",
    "\n",
    "nodecolor=x*1000\n",
    "\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "print(\"x(5):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periodicity of the graph does not allow a proper mixing of the opinions!\n",
    "\n",
    "Let us add a link to make the graph aperiodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.generators.lattice.grid_graph(dim=[2,2])\n",
    "G.add_edge((0,0),(1,1))\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run again the dynamics with same initial conditions as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,0,0,1])\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(1):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(2):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(3):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(4):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(5):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(10):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(15):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(20):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(25):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(30):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics goes to consensus.\n",
    "\n",
    "### Two questions\n",
    "- How fast the consensus is achieved?\n",
    "- What is the opinion that every node will eventually reach?\n",
    "\n",
    "We will answer to these questions later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 1 sink in the condensation graph: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(1,2),(2,1),(1,0),(0,2),(3,2),(3,4),(4,5),(5,4),(6,4),(5,6)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sinks does this graph have?\n",
    "\n",
    "Let us compute the condensation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "\n",
    "nx.draw(CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph has 2 sinks. Thus, the sufficient conditions under which the dynamics converges to consensus does not hold.\n",
    "\n",
    "Let us figure out why by an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics does not reach consensus.\n",
    "\n",
    "**Question**: can you intuitively understand why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now add a link in such a way that the condensation graph has now a single sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(6,3)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "nx.draw(CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compute the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x, \"\\n\")\n",
    "\n",
    "for n in range(199):\n",
    "    x = P @ x\n",
    "print(\"x(200):\", x, \"\\n\")\n",
    "\n",
    "for n in range(999):\n",
    "    x = P @ x\n",
    "print(\"x(1000):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reach consensus!!\n",
    "\n",
    "## Consensus value\n",
    "\n",
    "How is the consensus value computed?\n",
    "\n",
    "Let $\\pi$ denote the normalized left dominant eigenvector of $P$, i.e., the normalized $\\pi$ such that $P' \\pi = \\pi$ (which is unique because the graph has one sink only).\n",
    "We use the fact that\n",
    "\n",
    "$$\n",
    "\\pi' x(t) = \\pi' P x(t-1) = \\pi' x(t-1),\n",
    "$$\n",
    "\n",
    "thus $\\pi' x(t)$ is constant along the dynamics. Thus,\n",
    "\n",
    "$$\n",
    "\\pi' x(0) = \\pi' \\lim_{t \\to + \\infty} x(t) = \\alpha \\pi' \\mathbf{1} = \\alpha.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thie computation above says that the consensus value $\\alpha$ is the weighted average of the initial conditions of the nodes, where the weights are given by the (unique) invariant distribution $\\pi$.\n",
    "\n",
    "Recall that $\\pi$ solving $\\pi = P' \\pi$ is also the invariant distribution centrality, thus the more a node is central the more its initial opinion affects the consensus value.\n",
    "\n",
    "Let us explore the form of $\\pi$ for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = np.linalg.eig(P.T)\n",
    "\n",
    "# selects the eigenvalue 1 and print the eigenvector\n",
    "for index in [i for i in range(len(G)) if np.isclose(w[i],1)]: \n",
    "    pi = v[:,index].real  # -> eigenvectors are complex but pi is real, so we convert it to real\n",
    "    pi = pi/np.sum(pi)\n",
    "    print(\"pi\", index, \"=\", pi)\n",
    "    \n",
    "nx.draw(G,pos,with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The invariant distribution centrality is 0 for all the nodes that do not belong to the sink of the condensantion graph!\n",
    "\n",
    "This implies that the initial opinion of the nodes not belonging to the sink are negligible for the consensus value.\n",
    "\n",
    "The intuition for this is that the nodes 0, 1 and 2 do not care of the other nodes, because are not outconnected to any other node out of the component, and they reach consensus because the induced subgraph on 0,1,2 is aperiodic and strongly connected.\n",
    "Thus, their evolution is not affected by other nodes. Conversely, the other nodes update their opinion based on 2 also, thus eventually they tend to agree to the opinion of node 2 (and thus 0 and 1 as well).\n",
    "\n",
    "Let us modify the initial condition of nodes 3,4,5,6 to observe that the consensus value is not affected by this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial condition\n",
    "x = [1, 1, 0, 80, 25, 8, 12]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x, \"\\n\")\n",
    "\n",
    "for n in range(200):\n",
    "    x = P @ x\n",
    "print(\"x(300):\", x, \"\\n\")\n",
    "\n",
    "for n in range(1000):\n",
    "    x = P @ x\n",
    "print(\"x(1300):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed of convergence\n",
    "\n",
    "Let us work now for undirected (the following argument holds only for undirected) connected graphs. If the graph is also aperiodic, the dynamics is guaranteed to converge to consensus.\n",
    "\n",
    "Let $\\lambda:=\\max \\{\\lambda_2,|\\lambda_n|\\}$, where $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_n$ are the eigenvalues of $P$. $\\lambda_n \\ge -1$. \n",
    "\n",
    "You'll see in the next theoretical lectures that the dynamics reaches consensus exponentially fast. In particular, the distance from consensus at time $t$ is in some sense proportional to $\\lambda^t$ (this will be shown more formally in the theoretical lectures).\n",
    "\n",
    "Thus, if $\\lambda$ is close to $1$, then the convergence is slow, whereas if $\\lambda$ is small the convergence is faster.\n",
    "\n",
    "Note also that for periodic graphs, by Perron-Frobenius theorem have $\\lambda_n = -1$ (thus $\\lambda=1$), then the convergence to consensus is not achieved. This is coherent with the theory of consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: note that every periodic strongly connected graph can be made periodic by adding at least a selfloop in the graph. Indeed, if a selfloop $(i,i)$ is added, then the period of node $i$ is 1. Since all the nodes in the same connected component have same period, then all the nodes have period $1$ and the graph is aperiodic.\n",
    "\n",
    "To avoid periodic graphs, sometimes it is useful to introduce the **lazy dynamics** obtained by replacing $P$ with \n",
    "\n",
    "$$\n",
    "\\frac{P+\\mathbf{I}}{2}\n",
    "$$\n",
    "\n",
    "This is equivalent to adding selfloops to each node in the graph with weight equivalent to the degree of the node itself.\n",
    "\n",
    "An interpretation for the lazy dynamics is that nodes have some inertia in the opinion. Instead of averaging over the opinions of the neighbors, they also take into account their opinion at the previous step. In fact,\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\frac{x_i(t+1) + \\sum_{j} P_{ij} x_j(t)}{2}.\n",
    "$$\n",
    "\n",
    "Let us go back to the initial periodic example, and show that the lazy dynamics converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.generators.lattice.grid_graph(dim=[2,2])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = P/2 + np.diag(np.ones(4))/2\n",
    "\n",
    "x = np.array([1, 0, 0, 1])\n",
    "\n",
    "for n in range(9):\n",
    "    x = P @ x\n",
    "print(\"x(10):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How fast is the convergence of lazy dynamics?\n",
    "\n",
    "Note that $\\lambda_n(P_{lazy}) = 1/2 + \\lambda_n(P)/2 \\ge 1/2 + (-1/2) = 0$.\n",
    "\n",
    "Thus, $\\lambda = \\lambda_2$. \n",
    "\n",
    "In the lazy dynamics, the speed convergence is governed by $\\lambda_2$. Let us now define the relaxation time as\n",
    "\n",
    "$$\n",
    "\\tau_{rel} = \\frac{1}{1-\\lambda_2}\n",
    "$$\n",
    "\n",
    "You will see in the next theoretical lectures that for undirected graphs $\\lambda_2$ may be related to the level of connectedness of the graph. In particular, if the graph is well connected, $\\lambda_2$ is smaller and the convergence to consensus is faster.\n",
    "\n",
    "We do not investigate the details on how to define \"connectedness\" of graphs in proper way here. However, we can verify by a simple example how connectedness of the graph influences the speed of convergence.\n",
    "\n",
    "Let us consider a **cycle graph** with 1000 nodes.\n",
    "\n",
    "For the cycle graph one can show that\n",
    "\n",
    "$$\n",
    "\\lambda_2(P) = \\cos \\frac{2\\pi (n-1)}{n}.\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to + \\infty} \\lambda(P_{lazy}) = \\frac{1}{2} + \\lim_{n \\to + \\infty} \\frac{1}{2} \\cos \\frac{2\\pi}{n} = 1-\\frac{\\pi}{n},\n",
    "$$\n",
    "\n",
    "and the relaxation time for the cycle is\n",
    "\n",
    "$$\n",
    "\\tau_{rel} = \\frac{n}{\\pi}.\n",
    "$$\n",
    "\n",
    "This means that the convergence is achieved exponentially with a rate that scales linearly with $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(1000)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "P = P = P/2 + np.diag(np.ones(1000))/2\n",
    "\n",
    "# let us start with random initial conditions\n",
    "x = np.random.rand(1000)\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the complete graph, which is the most connected graph by definition. For the complete graph,\n",
    "\n",
    "$$\n",
    "W=\\mathbf{1}\\mathbf{1}'-I.\n",
    "$$\n",
    "\n",
    "Since $\\mathbf{1}\\mathbf{1}'$ has equal columns, it has rank $1$. Thus $\\mathbf{1}\\mathbf{1}'$ has $n-1$ eigenvalues equal to $0$. The remaining eigenvalue can be found by using the fact that the sum of the eigenvalues is the trace of the matrix. Since $=\\mathbf{1}\\mathbf{1}'-I$, the spectrum of $W$ is\n",
    "\n",
    "$$\n",
    "\\sigma_W = \\{n-1,-1,\\cdots,-1\\}\n",
    "$$\n",
    "\n",
    "Since the complete graph is regular and every node has graph 1, $P=W/(n-1)$\n",
    "Thus, the spectrum of $P$ is\n",
    "\n",
    "$$\n",
    "\\sigma_P = \\{1,-\\frac{1}{n-1},\\cdots,-\\frac{1}{n-1}\\},\n",
    "$$\n",
    "\n",
    "and $P_{lazy}$ has spectrum\n",
    "\n",
    "$$\n",
    "\\sigma_{P_{lazy}} = \\{1,-\\frac{1}{2(n-1)}+\\frac{1}{2},\\cdots,-\\frac{1}{2(n-1)}+\\frac{1}{2}\\}\n",
    "$$\n",
    "\n",
    "This implies that $\\lambda_2 = \\frac{n}{2(n-1)}$ and the relaxation time for large $n$ in the complete graph tends\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to +\\infty} \\tau_{rel} = 1/2,\n",
    "$$\n",
    "\n",
    "i.e., even for infinite $n$ the relaxation time is finite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(1000)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "P = P = P/2 + np.diag(np.ones(1000))/2\n",
    "\n",
    "# let us start with random initial conditions\n",
    "x = np.random.rand(1000)\n",
    "\n",
    "variance = np.var(x)\n",
    "n=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = P @ x\n",
    "    n=n+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisdom of crowds\n",
    "Consider a graph, and assume that state of each node represents a noisy estimate of the real state $\\mu$, i.e.,\n",
    "\n",
    "$$\n",
    "x_i = \\mu + y_i,\n",
    "$$\n",
    "\n",
    "with $E[y_i]=0$, and the variance $\\sigma^2 (y_i) = \\sigma^2$ for each $i$.\n",
    "\n",
    "Assume that the nodes of the graph talk each other, and assume that the graph is connected and aperiodic.\n",
    "Eventually, they will reach to consensus, i.e., $\\lim_{t \\to +\\infty} x(t) = \\alpha \\mathbf{1}$. \n",
    "\n",
    "Since $\\alpha = \\pi' (\\mu \\mathbf{1} + y)$, then\n",
    "\n",
    "$$\n",
    "E[\\alpha] = \\mu + \\pi' E[y] = \\mu, \\quad \\sigma_{\\alpha}^2 = \\sigma^2 \\sum_{i} \\pi_i^2 < \\sigma^2,\n",
    "$$\n",
    "\n",
    "because $\\sum_{i} \\pi_i^2 <1$ if the graph has more than one node.\n",
    "\n",
    "Obviously, $E[\\alpha]=\\mu$, because the noise $y_i$ is unbiased for each $i$. However, the interesting observation is that the estimate $\\alpha$ has a smaller variance than $\\sigma$, i.e., the crowd is able to reconstruct a more precise estimate of the real state than the single agents of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify this on a complete graph, where $\\pi_i = 1/n$, thus $\\sigma_\\alpha^2 = \\sigma^2/n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(100)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# start with random initial states and run the dynamics\n",
    "alfa_err = np.zeros(200)\n",
    "\n",
    "for i in range(200):\n",
    "# rand returns random values in [0,1], thus \\mu = 1/2\n",
    "    x = np.random.rand(100)\n",
    "    var = np.var(x)\n",
    "    for n in range(500):\n",
    "        x = P @ x\n",
    "    alfa_err[i] = (1/2 - np.mean(x))*(1/2 - np.mean(x))\n",
    "\n",
    "print(\"Variance of the node states:\", 1/12)\n",
    "print(\"Variance of the consensus state:\", np.mean(alfa_err), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the variance of $\\alpha$ is about $1/100$ of the original variance.\n",
    "\n",
    "Note that $\\sum_{i} \\pi_i^2$ tends to 1 if one node has almost all the centrality, and is minimal when the nodes have the same centrality (as in the complete graph, or in the cycle graph). This implies that if a graph is more 'democratic', then the consensus algorithm leads to better estimates of the true state. If a few nodes have all the centralities, the consensus is less precise.\n",
    "\n",
    "Let us see this with a another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(10)\n",
    "G = nx.Graph.to_directed(G)\n",
    "G.remove_edges_from([(0,1),(0,9)])\n",
    "G.add_edge(0,0)\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# start with random initial states and run the dynamics\n",
    "alfa_err = np.zeros(200)\n",
    "\n",
    "for i in range(200):\n",
    "# rand returns random values in [0,1], thus \\mu = 1/2\n",
    "    x = np.random.rand(10)\n",
    "    var = np.var(x)\n",
    "    for n in range(500):\n",
    "        x = P @ x\n",
    "    alfa_err[i] = (1/2 - np.mean(x))*(1/2 - np.mean(x))\n",
    "\n",
    "print(\"Expected variance of the node states:\", 1/12)\n",
    "print(\"Empirical variance of the consensus state:\", np.mean(alfa_err), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph the consensus value is exactly the initial state of node $0$, because the condensantion graph has 1 sink only, which is node $0$.\n",
    "\n",
    "$$\n",
    "\\pi = \\delta^{(0)}.\n",
    "$$\n",
    "\n",
    "This graph is the opposite of the complete graph, in the sense that all the invariant distribution centrality is on node $0$. Thus the variance of the consensus state equals the variance of the single state.\n",
    "\n",
    "Note that this argument holds independently of the size of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: linear flow dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of the lab we study how to simulate the linear averaging dynamics on graphs, which is the dual of linear averaging dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $G=(V,E,W)$ be a weighted graph, and $x(t) \\in \\mathrm{R}^{V}$ denote the total mass in the node of the graph.\n",
    "\n",
    "The dynamics of $x(t)$ reads\n",
    "\n",
    "$$\n",
    "x(t+1) = P'x(t),\n",
    "$$\n",
    "\n",
    "where $P$ is the normalized adjacency matrix of the graph and is called in this context the **routing matrix**.\n",
    "The routing matrix has the following interpretation: if $x_j$ is the total mass in node $j$, $P_{ji}$ is the fraction of the mass that will be routed in node $i$ at the next step, i.e.,\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\sum_{j} P_{ji} x_j(t)\n",
    "$$\n",
    "\n",
    "**Dual theorem**: assume that\n",
    "- its condensation graph has 1 sink;\n",
    "- the sink component of the graph is aperiodic;\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} x(t) = \\beta \\pi, \\quad \\beta = \\mathbf{1}' x(0)\n",
    "$$\n",
    "\n",
    "i.e., the mass distribution will eventually converge to the invariant distribution centrality of the network, where the proportionality factor can be computed by using the fact that the total mass on the network is preserved, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathbf{1}' x(t) = \\mathbf{1}' P' x(t-1) = \\mathbf{1}' x(t-1).\n",
    "$$\n",
    "\n",
    "**Observation**: note that this problem is the dual of the averaging dynamics, in the sense that in the averaging $\\pi' x(t)$ is constant and the dynamics converges to a state proportional to $\\mathbf{1}$, whereas in the flow dynamics $\\mathbf{1}' x(t)$ is constant and the dynamics converges to a state proportional to $\\pi$.\n",
    "\n",
    "**Observation**: note that the Theorem implies that under some conditions on the graph the invariant distribution centrality may be compute iteratively, by running the linear flow dynamics and normalizing the asymptotic state of the dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear flow dynamics with multiple sinks (of the condensation graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(1,2),(2,1),(1,0),(0,2),(3,2),(3,4),(4,5),(5,4),(6,4),(5,6)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,2,3,1,6])\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "x = P.T @ x\n",
    "print(\"x(1):\", x)\n",
    "\n",
    "x = P.T @ x\n",
    "print(\"x(2):\", x)\n",
    "\n",
    "x = P.T @ x\n",
    "print(\"x(3):\", x)\n",
    "\n",
    "x = P.T @ x\n",
    "print(\"x(4):\", x)\n",
    "\n",
    "x = P.T @ x\n",
    "print(\"x(5):\", x)\n",
    "\n",
    "x = P.T @ P.T @ P.T @ P.T @ P.T @ x\n",
    "print(\"x(10):\", x)\n",
    "\n",
    "x = P.T @ P.T @ P.T @ P.T @ P.T @ x\n",
    "print(\"x(15):\", x)\n",
    "\n",
    "x = P.T @ P.T @ P.T @ P.T @ P.T @ x\n",
    "print(\"x(20):\", x)\n",
    "\n",
    "x = P.T @ P.T @ P.T @ P.T @ P.T @ x\n",
    "print(\"x(25):\", x)\n",
    "\n",
    "x = P.T @ P.T @ P.T @ P.T @ P.T @ x\n",
    "print(\"x(30):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** Note that in node 3 the mass converges to 0. Why?\n",
    "\n",
    "**Question 2** Can you use the asymptotic state of the dynamics to deduce all the invariant distribution probabilities of the graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear flow dynamics on graph whose condensation graph has a unique sink (but not strongly connected)\n",
    "\n",
    "Let us now add a link in such a way that the condensation graph has now a single sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(6,3)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** What kind of asymptotic state do you expect for this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(999):\n",
    "    x = P.T @ x\n",
    "print(\"x(1000):\", x, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "If the graph is not strongly connected, but still its condensation graph has one sink:\n",
    "- the averaging dynamics converges to a consensus, whose value depends only on the initial state of nodes of the sink;\n",
    "- the linear flow dynamics converges to the dominant eigenvector of $P'$, which has support only on the nodes of the sink."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duality of the problems\n",
    "We are given an aperiodic graph whose condensiation graph has 1 sink, and the initial state $x(0)$.\n",
    "\n",
    "We can compute the asymptotic consensus value without running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from([0,1,2,3,4,5,6])\n",
    "G.add_edges_from([(1,2),(2,1),(1,0),(0,2),(3,2),(3,4),(4,5),(5,4),(6,4),(5,6),(6,3),(0,3)])\n",
    "# labels of nodes are couples: (column,row)\n",
    "nx.draw(G, pos, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(7)\n",
    "\n",
    "# compute \\pi by running the mass dynamics with a normalized initial condition y\n",
    "# the asymptotic state will be exactly \\pi.\n",
    "\n",
    "y = np.random.rand(7)\n",
    "y = y/np.sum(y)\n",
    "\n",
    "for iter in range(500):\n",
    "    y = P.T @ y\n",
    "\n",
    "# the consensus value is pi.T @ x, but y(t) --> \\pi, thus we can use y instead of \\pi.\n",
    "print(\"The consensus value:\", y.T @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result by running the averaging dynamics\n",
    "for iter in range(500):\n",
    "    x = P @ x\n",
    "    \n",
    "print(\"The asymptotic state x:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: distributed computation of average\n",
    "\n",
    "Let the node set describe a set of sensors that are deployed in some region in order to collect measurements of some quantity of interest (for example, the temperature). \n",
    "\n",
    "Assume that these sensors have limited communication and computation capabilities that allow each of them to exchange information only with those other sensors that are close enough in space. \n",
    "\n",
    "Let the graph $G = (V, E)$ describe the pattern of vicinity among the sensors $i$ and $j$ so that there is an undirected link between node $i$ and node $j$ if they can communicate to each other (possibly using link weights decreasing with distance). Then, one can design a distributed algorithm for computing the average of the sensor's measurements based on the averaging dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x_i(0)$ be the measurement of each node. \n",
    "\n",
    "We are interested in designing an iterative distributed algorithm that allows the nodes to compute\n",
    "\n",
    "$$\n",
    "x = \\frac{1}{n}\\sum_i x_i(0)\n",
    "$$\n",
    "\n",
    "**First attempt**\n",
    "We run a consensus algorithm. Since the graph is undirected, $\\pi_i = \\frac{w_i}{\\sum_j w_j}$. Thus, the algorithm converges to a consensus $\\alpha \\mathbf{1}$ such that\n",
    "\n",
    "$$\n",
    "\\alpha = \\sum_{i} \\frac{w_i}{w} x_i(0).\n",
    "$$\n",
    "\n",
    "If each edge knows its degree $w_i$, each node can rescale its initial state, i.e., $y_i(0) = \\frac{x_i(0)}{w_i}$. The consensus algorithm for the variable $y_i$ thus converges to\n",
    "\n",
    "$$\n",
    "\\alpha_y = \\sum_{i} \\frac{w_i}{w} y_i(0) = \\frac{1}{w} \\sum_{i} x_i(0).\n",
    "$$\n",
    "\n",
    "If we assume that each node knows the average degree of the network, thus\n",
    "\n",
    "$$\n",
    "x = \\alpha_y \\frac{w}{n} = \\alpha_y \\overline{w}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)\n",
    "\n",
    "n_nodes = len(G)\n",
    "\n",
    "x = np.random.rand(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us run the consensus algorithm for y\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "y = x/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    y = P @ y\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus on y\n",
    "print(\"average computed distributively\", y[0] * np.sum(degrees) / n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works! Unfortunately, requiring that each node knows the average degree of the network is not realistic.\n",
    "\n",
    "However, there exists another way to solve the problem.\n",
    "\n",
    "We run a second averaging dynamics, with initial condition $z_i(0) = \\frac{1}{w_i}$.\n",
    "\n",
    "This converges to\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to + \\infty} z_i(t) = \\sum_i z_i(0) \\frac{w_i}{w} = \\sum_{i} \\frac{1}{w} = \\frac{1}{\\overline{w}}\n",
    "$$\n",
    "\n",
    "By combining the two, each node can estimate the average estimate by \n",
    "\n",
    "$$\n",
    "\\frac{\\lim_{t \\to + \\infty} y_i(t)}{\\lim_{t \\to + \\infty} z_i(t)} =\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us implement this\n",
    "\n",
    "z = 1/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    z = P @ z\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus both on y and z\n",
    "print(\"average computed distributively\", y[0] / z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
